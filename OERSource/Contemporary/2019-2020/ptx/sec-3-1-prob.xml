<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-3-1-prob">

	<title>Probability</title>

	<subsection><title>Introduction</title>
	<p>The probability of a specified event is the chance or likelihood that it will occur.  There are several ways of viewing probability.  One would be <term>experimental</term> in nature, where we repeatedly conduct an experiment.  Suppose we flipped a coin over and over and over again and it came up heads about half of the time; we would expect that in the future whenever we flipped the coin it would turn up heads about half of the time.  When a weather reporter says “there is a 10% chance of rain tomorrow,” she is basing that on prior evidence; that out of all days with similar weather patterns, it has rained on 1 out of 10 of those days.</p>

	<p>Another view would be <term>subjective</term> in nature, in other words an educated guess.  If someone asked you the probability that the Seattle Mariners would win their next baseball game, it would be impossible to conduct an experiment where the same two teams played each other repeatedly, each time with the same starting lineup and starting pitchers, each starting at the same time of day on the same field under the precisely the same conditions.  Since there are so many variables to take into account, someone familiar with baseball and with the two teams involved might make an educated guess that there is a 75% chance they will win the game; that is, if the same two teams were to play each other repeatedly under identical conditions, the Mariners would win about three out of every four games.  But this is just a guess, with no way to verify its accuracy, and depending upon how educated the educated guesser is, a subjective probability may not be worth very much.</p>

	<p>We will return to the experimental and subjective probabilities from time to time, but in this course we will mostly be concerned with <term>theoretical</term> probability, which is defined as follows: Suppose there is a situation with n <u>equally likely</u> possible outcomes and that m of those n outcomes correspond to a particular event; then the <term>probability</term> of that event is defined as <m> \frac{m}{n} </m>.</p>

</subsection>

<subsection><title>Basic Concepts</title>

	<p>If you roll a die, pick a card from deck of playing cards, or randomly select a person and observe their hair color, we are executing an experiment or procedure.  In probability, we look at the likelihood of different outcomes.  We begin with some terminology. </p>

	<assemblage>
		<title>Events and Outcomes</title>
		<p>The result of an experiment is called an <term>outcome</term>.</p>

		<p>An <term>event</term> is any particular outcome or group of outcomes.</p>

		<p>A <term>simple event</term> is an event that cannot be broken down further.</p>

		<p>The <term>sample space</term> is the set of all possible sample events.</p>
	</assemblage>

	<example>
		<p>If we roll a standard 6-sided die, describe the sample space and some simple events.</p>

		<p>The sample space is the set of all possible simple events: {1,2,3,4,5,6}</p>

		<p>Some examples of simple events:

		<ul>
			<li>We roll a 1</li>
			<li>We roll a 5</li>
		</ul>
		</p>

		<p>Some compound events:

		<ul>
			<li>We roll a number bigger than 4</li>
			<li>We roll an even number</li>
		</ul>
		</p>
		
	</example>

	<assemblage>
		<title>Basic Probability</title>

		<p>Given that all outcomes are equally likely, we can compute the probability of an event E using this formula:</p>

		<p><me>P(E) = \frac{\text{Number of outcomes corresponding to the event E}}{\text{Total number of equally likely outcomes}}</me></p>
	</assemblage>

	<example>
		<p>If we roll a 6-sided die, calculate:

			<ol>
				<li>P(rolling a 1)</li>
				<li>P(rolling a 6)</li>
			</ol>
		</p>

		<p>Recall that the possible outcomes are {1,2,3,4,5,6}</p>

		<p>
			<ol> 
				<li>There is one outcome corresponding to “rolling a 1”, so the probability is <m>\frac{1}{6}</m></li>
				<li>There are two outcomes bigger than a 4, so the probability is <m>\frac{2}{6}=\frac{1}{3}</m></li>
			</ol>
		</p>
	</example>

<p>Probabilities are essentially fractions, and can be reduced to lower terms like fractions.</p>

<example>
	<p>Let's say you have a bag with 20 cherries, 14 sweet and 6 sour. If you pick a cherry at random, what is the probability that it will be sweet? </p>

	<p>There are 20 possible cherries that could be picked, so the number of possible outcomes is 20. Of these 20 possible outcomes, 14 are favorable (sweet), so the probability that the cherry will be sweet is <m> \frac{14}{20} = \frac{7}{10} </m>.</p>
</example>

<p>There is one potential complication to this example, however. It must be assumed that the probability of picking any of the cherries is the same as the probability of picking any other. This wouldn't be true if (let us imagine) the sweet cherries are smaller than the sour ones. (The sour cherries would come to hand more readily when you sampled from the bag.) Let us keep in mind, therefore, that when we assess probabilities in terms of the ratio of favorable to all potential cases, we rely heavily on the assumption of equal probability for all outcomes.</p>

<exploration>
	<p>At some random moment, you look at your clock and note the minutes reading.</p>

	<ol>
		<li>What is the probability the minutes reading is 15?</li>
		<li>What is the probability the minutes reading is 15 or less?</li>
	</ol>
</exploration>


<assemblage>
	<title>Cards</title>

	<p>A standard deck of 52 playing cards consists of four <term>suits</term> (hearts, spades, diamonds and clubs). Spades and clubs are black while hearts and diamonds are red. Each suit contains 13 cards, each of a different <term>rank</term>: an Ace (which in many games functions as both a low card and a high card), cards numbered 2 through 10, a Jack, a Queen and a King.</p>
</assemblage>

<example>
	<p>Compute the probability of randomly drawing one card from a deck and getting an Ace.</p>

	<p>There are 52 cards in the deck and 4 Aces so P(Ace) = <m>\frac{4}{52} = \frac{1}{13} \approx 0.0769 </m> </p>

	<p>We can also think of probabilities as percents: There is a 7.69% chance that a randomly selected card will be an Ace.</p>
</example>

<p>Notice that the smallest possible probability is 0 – if there are no outcomes that correspond with the event.  The largest possible probability is 1 – if all possible outcomes correspond with the event.</p>

<assemblage>
	<title>Certain and Impossible events</title>
	<p>An impossible event has a probability of 0.</p>
	<p>A certain event has a probability of 1.</p>
	<p>The probability of any event must be <m>0 \leq P(E) \leq 1</m></p>
</assemblage>

<p>In the course of this chapter, if you compute a probability and get an answer that is negative or greater than 1, you have made a mistake and should check your work.</p>

</subsection>

<subsection><title>Complementary Events</title>

<p>Now let us examine the probability that an event does <term>not</term> happen. As in the previous section, consider the situation of rolling a six-sided die and first compute the probability of rolling a six: the answer is P(six) =1/6. Now consider the probability that we do not roll a six: there are 5 outcomes that are not a six, so the answer is P(not a six) = <m> \frac{5}{6}</m> . Notice that P(six)+P(not a six) = <m> \frac{1}{6} + \frac{5}{6} = \frac{6}{6} = 1</m></p>

<p>This is not a coincidence.  Consider a generic situation with n possible outcomes and an event E that corresponds to m of these outcomes. Then the remaining n - m outcomes correspond to E not happening, thus</p>

<p>P(not E) = <m> \frac{n-m}{n} = \frac{n}{n}-\frac{m}{n}=1</m> - P(E) </p>

<assemblage>
	<title>Complement of an Event</title>
		<p>The <term>complement</term> of an event is the event "E doesn't happen".</p>

		<p>The notation <m>\overline{E}</m> is used for the complement of an event <m>E</m>.</p>

		<p>We can compute the probability of the complement using <m>P(\overline{E}) = 1-P(E)</m></p>

		<p>Notice also that <m>P(E) = 1-P(\overline{E})</m></p>
</assemblage>

<example>
	<p>If you pull a random card from a deck of playing cards, what is the probability it is not a heart?</p>

	<p>There are 13 hearts in the deck, so P(heart)=<m>\frac{13}{52}=\frac{1}{4}</m></p>

	<p>The probability of not drawing a heart is in the complement:</p>

	<p>P(not heart) = 1-P(heart) = <m>1-\frac{1}{4}=\frac{3}{4}</m></p>
</example>

</subsection>

<subsection>
	<title>Probability of two indepdent events</title>

<example>
	<p>Suppose we flipped a coin and rolled a die, and wanted to know the probability of getting a head on the coin and a 6 on the die.</p>

	<p>We could list all possible outcomes:   {H1,H2,H3,H4,H5,H6,T1,T2,T3,T4,T5,T6}.</p>

	<p>Notice there are <m>2 \cdot 6 = 12</m> total outcomes. Out of these, only 1 is the desired outcome, so the probability is  <m>\frac{1}{12}</m>.</p>

</example>

<p>The prior example was looking at two independent events.</p>

<assemblage>
	<title>Indepdentent Events</title>
	<p>Events A and B are <term>independent events</term> if the probability of Event B occurring is the same whether or not Event A occurs.</p>
</assemblage>

<example>
	<p>Are these events independent?</p>

	<p><ol>
		<li>A fair coin is tossed two times.  The two events are (1) first toss is a head and (2) second toss is a head.</li>

		<li>The two events (1) "It will rain tomorrow in Houston" and (2) "It will rain tomorrow in Galveston” (a city near Houston).</li>

		<li>You draw a card from a deck, then draw a second card without replacing the first.</li>
	</ol></p>

	<p><oL>
		<li>The probability that a head comes up on the second toss is 1/2 regardless of whether or not a head came up on the first toss, so these events are independent.</li>

		<li>These events are not independent because it is more likely that it will rain in Galveston on days it rains in Houston than on days it does not.</li>

		<li>The probability of the second card being red depends on whether the first card is red or not, so these events are not independent.</li>
	</oL></p>
</example>

<p>When two events are independent, the probability of both occurring is the product of the probabilities of the individual events. </p>

<assemblage>
	<title>P(A and B) for indepdent events</title>

	<p>If events A and B are independent, then the probability of both A and B occurring is</p>

	<p><me>P(A \text{ and } B) = P(A) \cdot P(B)</me></p>

	<p>where P(A and B) is the probability of events A and B both occurring, P(A) is the probability of event A occurring, and P(B) is the probability of event B occurring.</p>
</assemblage>

<p>If you look back at the coin and die example from earlier, you can see how the number of outcomes of the first event multiplied by the number of outcomes in the second event multiplied to equal the total number of possible outcomes in the combined event.</p>

<example>
	<p>In your drawer you have 10 pairs of socks, 6 of which are white, and 7 tee shirts, 3 of which are white.  If you randomly reach in and pull out a pair of socks and a tee shirt, what is the probability both are white?</p>

	<p>The probability of choosing a white pair of socks is <m>\frac{6}{10}</m>.</p>

	<p>The probability of choosing a white tee shirt is  <m>\frac{3}{7}</m>.</p>

	<p>The probability of both being white is <m> \frac{6}{10} \cdot \frac{3}{7} = \frac{18}{70} = \frac{9}{35}</m></p>
</example>

<exploration>
	<p>A card is pulled a deck of cards and noted.  The card is then replaced, the deck is shuffled, and a second card is removed and noted.  What is the probability that both cards are Aces?</p>
</exploration>

<p>The previous examples looked at the probability of both events occurring.  Now we will look at the probability of either event occurring.</p> 


</subsection>


  </section>
