<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-1-5-how-to-mess">

	<title>1.5 How to Mess Things Up Before You Start</title>

	<p>There are number of ways that a study can be ruined before you even start collecting data.  The first we have already explored – <term>sampling</term> or <term>selection bias</term>, which is when the sample is not representative of the population.  One example of this is <term>voluntary response bias</term>, which is bias introduced by only collecting data from those who volunteer to participate.  This is not the only potential source of bias.</p>

	<assemblage>
		<title>Sources of bias</title>
		<p><term>Sampling bias</term> – when the sample is not representative of the population</p>
		<p><term>Voluntary response bias</term> – the sampling bias that often occurs when the sample is volunteers</p>
		<p><term>Self-interest study</term> – bias that can occur when the researchers have an interest in the outcome</p>
		<p><term>Response bias</term>– when the responder gives inaccurate responses for any reason</p>
		<p><term>Perceived lack of anonymity</term> – when the responder fears giving an honest answer might negatively affect them</p>
		<p><term>Loaded questions</term> – when the question wording influences the responses</p>
		<p><term>Non-response bias</term> – when people refusing to participate in the study can influence the validity of the outcome</p>
	</assemblage>

	<example>
		<p>Consider a recent study which found that chewing gum may raise math grades in teenagers .  This study was conducted by the Wrigley Science Institute, a branch of the Wrigley chewing gum company.  This is an example of a <term>self-interest study</term>; one in which the researches have a vested interest in the outcome of the study.  While this does not necessarily ensure that the study was biased, it certainly suggests that we should subject the study to extra scrutiny.</p>
	</example>

	<example>
		<p>A survey asks people “when was the last time you visited your doctor?”  This might suffer from <term>response bias</term>, since many people might not remember exactly when they last saw a doctor and give inaccurate responses.</p>
	</example>

	<p>Sources of response bias may be innocent, such as bad memory, or as intentional as pressuring by the pollster.  Consider, for example, how many voting initiative petitions people sign without even reading them.</p>

	<example>
		<p>A survey asks participants a question about their interactions with members of other races.  Here, a <term>perceived lack of anonymity</term> could influence the outcome.  The respondent might not want to be perceived as racist even if they are, and give an untruthful answer.</p>
	</example>

	<example>
		<p>An employer puts out a survey asking their employees if they have a drug abuse problem and need treatment help.  Here, answering truthfully might have consequences; responses might not be accurate if the employees do not feel their responses are anonymous or fear retribution from their employer.</p>
	</example>

	<example>
		<p>A survey asks “do you support funding research of alternative energy sources to reduce our reliance on high-polluting fossil fuels?”  This is an example of a <term>loaded</term> or <term>leading question</term> – questions whose wording leads the respondent towards an answer.  </p>
	</example>

	<p>Loaded questions can occur intentionally by pollsters with an agenda, or accidentally through poor question wording.  Also a concern is question order, where the order of questions changes the results.  A psychology researcher provides an example<fn> Swartz, Norbert. http://www.umich.edu/~newsinfo/MT/01/Fal01/mt6f01.html.  Retrieved 3/31/2009</fn></p>

	<p>“My favorite finding is this: we did a study where we asked students, 'How satisfied are you with your life? How often do you have a date?' The two answers were not statistically related - you would conclude that there is no relationship between dating frequency and life satisfaction. But when we reversed the order and asked, 'How often do you have a date? How satisfied are you with your life?' the statistical relationship was a strong one. You would now conclude that there is nothing as important in a student's life as dating frequency.”</p>

	<example>
		<p>A telephone poll asks the question “Do you often have time to relax and read a book?”, and 50% of the people called refused to answer the survey.  It is unlikely that the results will be representative of the entire population.  This is an example of <term>non-response bias</term>, introduced by people refusing to participate in a study or dropping out of an experiment.  When people refuse to participate, we can no longer be so certain that our sample is representative of the population.</p>
	</example>

	<exploration>
		<statement><p>In each situation, identify a potential source of bias
			<ol>
				<li>A survey asks how many sexual partners a person has had in the last year</li>
				<li>A radio station asks readers to phone in their choice in a daily poll.</li>
				<li>A substitute teacher wants to know how students in the class did on their last test. The teacher asks the 10 students sitting in the front row to state their latest test score.</li>
				<li>High school students are asked if they have consumed alcohol in the last two weeks.</li>
				<li>The Beef Council releases a study stating that consuming red meat poses little cardiovascular risk.</li>
				<li>A poll asks “Do you support a new transportation tax, or would you prefer to see our public transportation system fall apart?”</li>
			</ol>
		</p></statement>
		<solution>
			<ol>
				<li>Response bias – historically, men are likely to over-report, and women are likely to under-report to this question.</li>
    			<li>Voluntary response bias – the sample is self-selected</li>
   				<li>Sampling bias – the sample may not be representative of the whole class</li>
    			<li>Lack of anonymity</li>
    			<li>Self-interest study</li>
    			<li>Loaded question</li>
    		</ol>
    	</solution>

	</exploration>


</section>
